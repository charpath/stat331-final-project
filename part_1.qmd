---
title: "STAT 331 Final Project"
subtitle: "Part 1"
author: "Charles Jansen, Stanley Lam, Minh Ho-Hoang, James Lamkin"
format: 
  html:
    theme: default
    code-tools: true
    toc: true
    embed-resources: true
    code-fold: true
execute: 
  echo: true
  eval: true
  error: true
  message: false
  warning: false
---

## Part 1: Project Proposal + Data

### Data Description

```{r setup}
# Load necessary libraries here
library(tidyverse)
library(knitr)
library(kableExtra)
```

```{r}
# Load data here
murders <- read_csv("murder_per_100000_people.csv")
unemployment <- read_csv("long_term_unemployment_rate_percent.csv")
```

The data used in this analysis originates from the Gapminder Foundation, an independent educational non-profit organization dedicated to fighting global misconceptions. We have specifically utilized two datasets from their collection: "Murders per 100,000 People" and "Long-Term Unemployment Rate". These datasets provide insights into societal trends across various countries over time.

##### "Murders per 100,000 People" Dataset 
This dataset contains the annual number of murders per 100,000 people for various countries, spanning from 1950 to 2016. It offers a measure of violent crime rates, providing a crucial indicator of societal safety and stability.

##### "Long-Term Unemployment Rate (Percentage)" Dataset
This dataset presents the annual long-term unemployment rate as a percentage of the labor force for various countries, covering the period from 1990 to 2020. Long-term unemployment is defined as individuals who have been unemployed for a year or longer. This metric serves as an indicator of economic health and labor market stability.

These datasets were chosen to explore the potential relationship between long-term unemployment rates and murder rates. The hypothesis is that economic factors, such as long-term unemployment, may correlate with societal indicators of violence.


### Cleaning Murders Data

First, we'll start with the murders dataset. We can take a look to see if there's anything that clearly needs to change:

```{r}
head(murders) |> 
  kable()
```

The types of all of the columns seem correct: The country is represented as a character vector, and all of the actual murder rates are numerical. It doesn't seem like we'll need any particular cleaning, so we'll go ahead and pivot our data.

We want to pivot every column that isn't the country into two columns: The year, and the murders per 100,000 in that country and that year.

Additionally, we can convert the year to a number, and drop any rows that do not have an observation for the murders per 100,000.

```{r}
murders_clean <- murders |> 
  pivot_longer(cols = !country, names_to = "year", values_to = "murders_per_100000") |> 
  mutate(year = as.numeric(year)) |> 
  filter(!is.na(murders_per_100000))

head(murders_clean) |> 
  kable(align = "ccc")
```

### Cleaning Unemployment Data

Now that the murders data is clean and pivoted, what about the unemployment data?

First, we should take a look at the data:

```{r}
head(unemployment) |> 
  kable()
```

Similarly to the murders data, looks good from the start! We'll do the exact same thing to this data as we did to the murders data: Pivot all of the observation columns into one year column and one unemployment rate column, then convert year to a number and drop all missing observations.

```{r}
unemployment_clean <- unemployment |> 
  pivot_longer(cols = !country, names_to = "year", values_to = "long_term_unemployment_rate") |> 
  mutate(year = as.numeric(year)) |> 
  filter(!is.na(long_term_unemployment_rate))

head(unemployment_clean) |> 
  kable(align = "ccc")
```

### Joining Datasets

Before we join the two datasets, I'd like to make a note:

```{r}
data.frame("Unemployment" = range(unemployment_clean$year),
           "Murders" = range(murders_clean$year),
           row.names = c("Earliest Observation", "Latest Observation")) |> 
  kable()
```

As we can see from this table, the unemployment data only goes from 1990 to 2020, while the murders data spans all the way from 1950 to 2016. This means, after joining the two datasets, we will only be able to work with data from 1990 to 2016, or about 26 years worth of data. This shouldn't have a huge impact on anything, but it's good to keep in mind.

Now that that's out of the way, we can join the two datasets into one variable. One thing to keep in mind is that we'll only be keeping year-country combinations that have an observation for both unemployment rate and murders per 100,000.

```{r}
murders_unemployment <-
  inner_join(murders_clean, unemployment_clean,
             by = join_by(country == country, year == year))

head(murders_unemployment) |> 
  kable(align = "cccc")
```

There it is! We have our two datasets fully cleaned and joined into one table that we can continue to work with.
