---
title: "STAT 331 Final Project"
subtitle: "Project"
author: "Charles Jansen, Stanley Lam, Minh Ho-Hoang"
format: 
  html:
    theme: default
    code-tools: true
    toc: true
    embed-resources: true
    code-fold: true
execute: 
  echo: true
  eval: true
  error: true
  message: false
  warning: false
---

## Part 1: Project Proposal + Data

### Data Description

```{r setup}
# Load necessary libraries here
library(tidyverse)
library(knitr)
library(kableExtra)
library(gganimate)
library(gifski)
```

```{r}
# Load data here
murders <- read_csv("murder_per_100000_people.csv")
unemployment <- read_csv("long_term_unemployment_rate_percent.csv")
```

The data used in this analysis originates from the Gapminder Foundation, an independent educational non-profit organization dedicated to fighting global misconceptions. We have specifically utilized two datasets from their collection: "Murder per 100,000 People" and "Long-Term Unemployment Rate". These datasets provide insights into societal trends across various countries over time.

##### "Murder per 100,000 People" Dataset 
This dataset contains the annual number of murders per 100,000 people for various countries, spanning from 1950 to 2016. It offers a measure of violent crime rates, providing a crucial indicator of societal safety and stability.

##### "Long-Term Unemployment Rate (Percentage)" Dataset
This dataset presents the annual long-term unemployment rate as a percentage of the labor force for various countries, covering the period from 1990 to 2020. Long-term unemployment is defined as individuals who have been unemployed for a year or longer. This metric serves as an indicator of economic health and labor market stability.

**VARIABLES ARE:**

**LONG TERM EMPLOYMENT RATE (%)** - Represents the percentage of the labor force that has been unemployed for a year or more.

**MURDERS PER 100,000 PEOPLE** - Represents the number of murders per 100,000 individuals in a given population.

These datasets were chosen to explore the potential relationship between long-term unemployment rates and murder rates. The hypothesis is that economic factors, such as long-term unemployment, may correlate with societal indicators of violence.


### Cleaning Murders Data

First, we'll start with the murders dataset. We can take a look to see if there's anything that clearly needs to change:

```{r}
head(murders) |> 
  kable()
```

The types of all of the columns seem correct: The country is represented as a character vector, and all of the actual murder rates are numerical. It doesn't seem like we'll need any particular cleaning, so we'll go ahead and pivot our data.

We want to pivot every column that isn't the country into two columns: The year, and the murders per 100,000 in that country and that year.

Additionally, we can convert the year to a number, and drop any rows that do not have an observation for the murders per 100,000.

```{r}
murders_clean <- murders |> 
  pivot_longer(cols = !country, names_to = "year", values_to = "murders_per_100000") |> 
  mutate(year = as.numeric(year)) |> 
  filter(!is.na(murders_per_100000))

head(murders_clean) |> 
  kable(align = "ccc")
```

### Cleaning Unemployment Data

Now that the murders data is clean and pivoted, what about the unemployment data?

First, we should take a look at the data:

```{r}
head(unemployment) |> 
  kable()
```

Similarly to the murders data, looks good from the start! We'll do the exact same thing to this data as we did to the murders data: Pivot all of the observation columns into one year column and one unemployment rate column, then convert year to a number and drop all missing observations.

```{r}
unemployment_clean <- unemployment |> 
  pivot_longer(cols = !country, names_to = "year", values_to = "long_term_unemployment_rate") |> 
  mutate(year = as.numeric(year)) |> 
  filter(!is.na(long_term_unemployment_rate))

head(unemployment_clean) |> 
  kable(align = "ccc")
```

### Joining Datasets

Before we join the two datasets, I'd like to make a note:

```{r}
data.frame("Unemployment" = range(unemployment_clean$year),
           "Murders" = range(murders_clean$year),
           row.names = c("Earliest Observation", "Latest Observation")) |> 
  kable()
```

As we can see from this table, the unemployment data only goes from 1990 to 2020, while the murders data spans all the way from 1950 to 2016. This means, after joining the two datasets, we will only be able to work with data from 1990 to 2016, or about 26 years worth of data. This shouldn't have a huge impact on anything, but it's good to keep in mind.

Now that that's out of the way, we can join the two datasets into one variable. One thing to keep in mind is that we'll only be keeping year-country combinations that have an observation for both unemployment rate and murders per 100,000.

```{r}
murders_unemployment <-
  inner_join(murders_clean, unemployment_clean,
             by = join_by(country == country, year == year))

head(murders_unemployment) |> 
  kable(align = "cccc")
```

There it is! We have our two datasets fully cleaned and joined into one table that we can continue to work with.

=======

## Part 2: Linear Regression

With the clean data, we will now compare the relationship between our two quantitative variables using a scatterplot. Unemployment will be our explanatory variable, while murder will be our response variable.

### Visual Plots

```{r}
murders_unemployment |>
  ggplot(aes(x = long_term_unemployment_rate, y = murders_per_100000)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Relationship Between Murder and Unemployment in Different Countries (1990 - 2016)",
       x = "Unemployment Rate (%)",
       subtitle = "Murder (1 per 100,000)") +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10))
```

When looking at the linear regression, it appears that there is a weak negative correlation between unemployment rate and murder rate. There is also multiple outliers, on the top of the scatterplot where murder rates are rampant. Now we will compare these values overtime to see if anything has changed over the years.

```{r}
anim <- murders_unemployment |>
  ggplot(aes(x = long_term_unemployment_rate, y = murders_per_100000)) +
  geom_point(size = 3) + 
  labs(title = "Year: {frame_time}",
       x = "Unemployment Rate (%)", y = "Murder (per 100,000") +
  transition_time(year) +
  ease_aes("linear")

animate(anim, renderer = gifski_renderer())
```

From the animated visual, there is not much we describe about the relationship between unemployment rate and murder rate. However, we are able to depict murder rate and unemployment rate seperately. In the late 1990s, we see murder rate spike up and gradually decrease as we enter the new millennium. And as the 2008 recession starts to hit, we see unemployment rate spike up for a couple of years.  




>>>>>>> d53b2bf8247bd713afdd3f04c1029415e25693bd:finalproject.qmd
